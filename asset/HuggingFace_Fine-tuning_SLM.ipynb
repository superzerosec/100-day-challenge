{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tuning a Small Language Model (SLM) with HuggingFace\n",
        "This notebook explains how to fully fine-tune a Small Language Model (SLM) on a custom dataset with HuggingFace Transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install trl accelerate gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import transformers \n",
        "import trl # trl = Transformers Reinforcement Learning -> https://github.com/huggingface/trl \n",
        "import datasets \n",
        "import accelerate\n",
        "\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU: NVIDIA RTX A4000\n",
            "Total Memory:     16750.15 MB | 16.75 GB\n",
            "Allocated Memory: 0.00 MB | 0.00 GB\n",
            "Reserved Memory:  0.00 MB | 0.00 GB\n",
            "Free Memory:      16750.15 MB | 16.75 GB\n"
          ]
        }
      ],
      "source": [
        "# Check the amount of GPU memory available (we need at least ~16GB)\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gpu_name = torch.cuda.get_device_name(device)\n",
        "    \n",
        "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
        "    allocated_memory = torch.cuda.memory_allocated(device)\n",
        "    reserved_memory = torch.cuda.memory_reserved(device)\n",
        "    free_memory = total_memory - reserved_memory\n",
        "    \n",
        "    print(f\"GPU: {gpu_name}\")\n",
        "    print(f\"Total Memory:     {total_memory / 1e6:.2f} MB | {total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Allocated Memory: {allocated_memory / 1e6:.2f} MB | {allocated_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Reserved Memory:  {reserved_memory / 1e6:.2f} MB | {reserved_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Free Memory:      {free_memory / 1e6:.2f} MB | {free_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"No CUDA GPU available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_NAME = \"google/gemma-3-270m-it\" # note: \"it\" stands for \"instruction tuned\" which means the model has been tuned for following instructions\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    dtype=\"auto\",\n",
        "    device_map=\"auto\", # put the model on the GPU\n",
        "    attn_implementation=\"eager\" # could use flash_attention_2 but ran into issues... so stick with Eager for now\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Model on device: cuda:1\n",
            "[INFO] Model using dtype: torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(f\"[INFO] Model on device: {model.device}\")\n",
        "print(f\"[INFO] Model using dtype: {model.dtype}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [2, 9259, 236764, 1217, 659, 611, 236881], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"Hello, how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "odict_keys(['logits', 'past_key_values'])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "outputs = model(torch.tensor(tokenizer(\"Hello my name is Daniel\")[\"input_ids\"]).unsqueeze(0).to(device))\n",
        "outputs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Number of samples in the dataset: 1420\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"mrdbourke/FoodExtract-1k\")\n",
        "\n",
        "print(f\"[INFO] Number of samples in the dataset: {len(dataset['train'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Input:\n",
            "Kg3+P9vSv\\euD U#<A67ouV(x'H&*:k.\\|.M:TkX]}Q<-i{`-JOY[LM3GPsE-adHjVvMt &W\"'U.bmp\n",
            "\n",
            "[INFO] Example structured output (what we want our model to learn to predict):\n",
            "{'is_food_or_drink': False, 'tags': [], 'food_items': [], 'drink_items': []}\n",
            "\n",
            "[INFO] Example output condensed (we'll train our model to predict the condensed output since it uses less tokens than JSON):\n",
            "food_or_drink: 0\n",
            "tags: \n",
            "foods: \n",
            "drinks:\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def get_random_idx(dataset):\n",
        "    \"\"\"Returns a random integer index based on the number of samples in the dataset.\"\"\"\n",
        "    random_idx = random.randint(0, len(dataset)-1)\n",
        "    return random_idx\n",
        "\n",
        "\n",
        "random_idx = get_random_idx(dataset[\"train\"])\n",
        "random_sample = dataset[\"train\"][random_idx]\n",
        "\n",
        "example_input = random_sample[\"sequence\"]\n",
        "example_output = random_sample[\"gpt-oss-120b-label\"]\n",
        "example_output_condensed = random_sample[\"gpt-oss-120b-label-condensed\"]\n",
        "\n",
        "print(f\"[INFO] Input:\\n{example_input}\")\n",
        "print()\n",
        "print(f\"[INFO] Example structured output (what we want our model to learn to predict):\")\n",
        "print(eval(example_output))\n",
        "print()\n",
        "print(f\"[INFO] Example output condensed (we'll train our model to predict the condensed output since it uses less tokens than JSON):\")\n",
        "print(example_output_condensed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Our fine-tuned model will assign tags to text so we can easily filter them by type in the future\n",
        "tags_dict = {'np': 'nutrition_panel',\n",
        " 'il': 'ingredient list',\n",
        " 'me': 'menu',\n",
        " 're': 'recipe',\n",
        " 'fi': 'food_items',\n",
        " 'di': 'drink_items',\n",
        " 'fa': 'food_advertistment',\n",
        " 'fp': 'food_packaging'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Format the dataset into LLM-style inputs/outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'Kg3+P9vSv\\\\euD U#<A67ouV(x\\'H&*:k.\\\\|.M:TkX]}Q<-i{`-JOY[LM3GPsE-adHjVvMt &W\"\\'U.bmp',\n",
              " 'image_url': None,\n",
              " 'class_label': 'not_food',\n",
              " 'source': 'random-string-generation',\n",
              " 'char_len': None,\n",
              " 'word_count': None,\n",
              " 'syn_or_real': 'syn',\n",
              " 'uuid': '77a2f514-2dad-4c06-b120-3494993360fc',\n",
              " 'gpt-oss-120b-label': \"{'is_food_or_drink': False, 'tags': [], 'food_items': [], 'drink_items': []}\",\n",
              " 'gpt-oss-120b-label-condensed': 'food_or_drink: 0\\ntags: \\nfoods: \\ndrinks:',\n",
              " 'target_food_names_to_use': None,\n",
              " 'caption_detail_level': None,\n",
              " 'num_foods': None,\n",
              " 'target_image_point_of_view': None}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [{'role': 'user',\n",
              "   'content': 'Kg3+P9vSv\\\\euD U#<A67ouV(x\\'H&*:k.\\\\|.M:TkX]}Q<-i{`-JOY[LM3GPsE-adHjVvMt &W\"\\'U.bmp'},\n",
              "  {'role': 'system', 'content': 'food_or_drink: 0\\ntags: \\nfoods: \\ndrinks:'}]}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def sample_to_conversation(sample):\n",
        "    \"\"\"Helper function to convert an input sample to conversation style.\"\"\"\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": sample[\"sequence\"]}, # Load the sequence from the dataset\n",
        "            {\"role\": \"system\", \"content\": sample[\"gpt-oss-120b-label-condensed\"]} # Load the gpt-oss-120b generated label\n",
        "        ]\n",
        "    }\n",
        "\n",
        "sample_to_conversation(random_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sequence': 'another optional quest takes place on windfall island during the night time play the song of passing a number of times and each time, glance towards the sky',\n",
              " 'image_url': 'https://portforward.com/games/walkthroughs/The-Legend-of-Zelda-The-Wind-Waker/The-Legend-of-Zelda-The-Wind-Waker-large-430.jpg',\n",
              " 'class_label': 'not_food',\n",
              " 'source': 'qwen2vl_open_dataset',\n",
              " 'char_len': 156.0,\n",
              " 'word_count': 28.0,\n",
              " 'syn_or_real': 'real',\n",
              " 'uuid': 'bbac79ce-df1f-48b8-891c-752809be11c7',\n",
              " 'gpt-oss-120b-label': \"{'is_food_or_drink': 'false', 'tags': [], 'food_items': [], 'drink_items': []}\",\n",
              " 'gpt-oss-120b-label-condensed': 'food_or_drink: 0\\ntags: \\nfoods: \\ndrinks:',\n",
              " 'target_food_names_to_use': None,\n",
              " 'caption_detail_level': None,\n",
              " 'num_foods': None,\n",
              " 'target_image_point_of_view': None,\n",
              " 'messages': [{'content': 'another optional quest takes place on windfall island during the night time play the song of passing a number of times and each time, glance towards the sky',\n",
              "   'role': 'user'},\n",
              "  {'content': 'food_or_drink: 0\\ntags: \\nfoods: \\ndrinks:', 'role': 'system'}]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Map our sample_to_conversation function to dataset \n",
        "dataset = dataset.map(sample_to_conversation,\n",
        "                      batched=False)\n",
        "\n",
        "dataset[\"train\"][42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sequence', 'image_url', 'class_label', 'source', 'char_len', 'word_count', 'syn_or_real', 'uuid', 'gpt-oss-120b-label', 'gpt-oss-120b-label-condensed', 'target_food_names_to_use', 'caption_detail_level', 'num_foods', 'target_image_point_of_view', 'messages'],\n",
              "        num_rows: 1136\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sequence', 'image_url', 'class_label', 'source', 'char_len', 'word_count', 'syn_or_real', 'uuid', 'gpt-oss-120b-label', 'gpt-oss-120b-label-condensed', 'target_food_names_to_use', 'caption_detail_level', 'num_foods', 'target_image_point_of_view', 'messages'],\n",
              "        num_rows: 284\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a train/test split\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2,\n",
        "                                            shuffle=False,\n",
        "                                            seed=42)\n",
        "\n",
        "# Number #1 rule in machine learning\n",
        "# Always train on the train set and test on the test set\n",
        "# This gives us an indication of how our model will perform in the real world\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNYzatJtFkfUqqdiR6rYwVL",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "01_pytorch_workflow_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
